{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_qa.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euwO4g3zXffl"
      },
      "source": [
        "# Question Answering with BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dtyw0F0XinX"
      },
      "source": [
        "In this notebook we’ll look at the particular type of extractive QA that involves answering a question about a passage by highlighting the segment of the passage that answers the question. This involves fine-tuning a model which predicts a start position and an end position in the passage. We will use the  [Stanford Question Answering Dataset (SQuAD) 2.0](https://rajpurkar.github.io/SQuAD-explorer/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX3kcwItoAj-"
      },
      "source": [
        "For this assignment, and since [BERT](https://huggingface.co/transformers/model_doc/bert.html) is available as a pre-trained model, we wil be fine-tuning it with the SQuAD dataset. We will be using the **BERT base** model, which consists of 12 layers (transformer blocks), 12 attention heads, 110 million parameters, and has an output size of 768-dimensions. \n",
        "\n",
        "Another option is to use [DistilBERT](https://huggingface.co/transformers/model_doc/distilbert.html) which is a small, fast, cheap and light Transformer model trained by distilling BERT base. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark.\n",
        "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='https://drive.google.com/uc?id=1CrQGxVis6cPgNDazA0xBWFQWpIK3VVSv' alt=\"alternate text\" width=\"width\" height=\"height\"/></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zlKT6dvvIv0"
      },
      "source": [
        "BERT was pre-trained on a large corpus of unlabelled text including the entire Wikipedia (that’s 2,500 million words) and book corpus (800 million words)\n",
        "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='https://drive.google.com/uc?id=1WZsEjjzBITh0I2YMUIKEeoPS8SdcMjHX' alt=\"alternate text\" width=\"500\" height=\"auto\"/></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snPMr2S7vysf"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qkc3Wb2rbBpX"
      },
      "source": [
        "Let's install transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMQIJIHpbF9G",
        "outputId": "44820c21-22d3-459e-d9ab-acb86c432d4e"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.16)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alhM-I0Rv1x9"
      },
      "source": [
        "## Download the SQuAD Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiBtZDVEv6El"
      },
      "source": [
        "We will download the SQuAD v2.0 dataset using the follwoing code. Fortunately, it is already available in both, a training (train-v2.0.json) and a validation (dev-v2.0.json) chunks. We however will need to prepare it for the model in the next steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGLfVMB1wJoT"
      },
      "source": [
        "import os\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "squad_folder = \"squad_data\" \n",
        "if not os.path.exists(squad_folder):\n",
        "    os.mkdir(squad_folder)\n",
        "\n",
        "url = 'https://rajpurkar.github.io/SQuAD-explorer/dataset/'\n",
        "res = requests.get(f'{url}train-v2.0.json')\n",
        "\n",
        "for file in ['train-v2.0.json', 'dev-v2.0.json']:\n",
        "    jfile = Path(f'{squad_folder}/{file}')\n",
        "    # check if files are downloaded already\n",
        "    if not jfile.exists():\n",
        "      # make the request to download data over HTTP\n",
        "      res = requests.get(f'{url}{file}')\n",
        "      # write to file\n",
        "      with open(f'{squad_folder}/{file}', 'wb') as f:\n",
        "          for chunk in res.iter_content(chunk_size=4):\n",
        "              f.write(chunk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR6WFE7fy4TZ"
      },
      "source": [
        "Let's look at the data, shall we!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLP8l-tjvx-m"
      },
      "source": [
        "import json\n",
        "\n",
        "file = 'train-v2.0.json'\n",
        "with open(f'{squad_folder}/{file}', 'r') as j:\n",
        "    parsed = json.load(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXyq1lhM0UQn",
        "outputId": "a5e8a946-90e2-4db7-ec31-baa310e31cd0"
      },
      "source": [
        "parsed.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['version', 'data'])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGztg2ch0XtS"
      },
      "source": [
        "# print(json.dumps(parsed['data'][:1][0], indent=2, sort_keys=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3-K6IgXRMe6"
      },
      "source": [
        "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='https://drive.google.com/uc?id=1BKdJEvlbLU5BoB2C54UV58avO5-xHl2o' alt=\"alternate text\" width=\"800\" height=\"auto\"/></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukAImqZT1VxG"
      },
      "source": [
        "The important pieces here are:\n",
        "- Contexts — Paragraphs that contain the answers to the questions\n",
        "- Questions — strings containing the question\n",
        "- Answers — strings which are ‘extracts’ of the given contexts that provide an answer to the questions\n",
        "\n",
        "While training, the model will read both the question and the answer, and return the token positions of the predicted answer from the context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfFo7DiiwVg4"
      },
      "source": [
        "## Prepare the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub2_l5p3-FFX"
      },
      "source": [
        "For this step, we will use the following function to extract the contexts, questions and answers from each data file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISyW-vbkwZF7"
      },
      "source": [
        "def read_squad(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        squad_dict = json.load(f)\n",
        "\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    # iterate through all data in squad data\n",
        "    for group in squad_dict['data']:\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']\n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                # check if we need to be extracting from 'answers' or 'plausible_answers'\n",
        "                if 'plausible_answers' in qa.keys():\n",
        "                    access = 'plausible_answers'\n",
        "                else:\n",
        "                    access = 'answers'\n",
        "                for answer in qa[access]:\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(answer)\n",
        "\n",
        "    return contexts, questions, answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzCQHvXLYwcy"
      },
      "source": [
        "# execute our read SQuAD function for training and validation sets\n",
        "train_contexts, train_questions, train_answers = read_squad(f'{squad_folder}/train-v2.0.json')\n",
        "val_contexts, val_questions, val_answers = read_squad(f'{squad_folder}/dev-v2.0.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIKly-oP6C87"
      },
      "source": [
        "# making sure our function above worked\n",
        "assert len(train_contexts) == len(train_questions) == len(train_answers)\n",
        "assert len(val_contexts) == len(val_questions) == len(val_answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSnQILsCOpel",
        "outputId": "d616594e-ec2c-49a2-89ac-4a7dcb4c927d"
      },
      "source": [
        "print(\"paragraph:\\n\", train_contexts[0])\n",
        "print(\"question:\\n\", train_questions[0])\n",
        "print(\"answer:\\n\", train_answers[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "paragraph:\n",
            " Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
            "question:\n",
            " When did Beyonce start becoming popular?\n",
            "answer:\n",
            " {'text': 'in the late 1990s', 'answer_start': 269}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-R3Fu2LUkNg"
      },
      "source": [
        "As we can see the answers are in a different format than the paragraphs and the questions. Each item of the answers is a dictionary where the answer is contained within the 'text', and the starting position of this answer within the context is also provided in `answer_start`.\n",
        "\n",
        "We need to train our model to find the start and end of our answer within the context, so we need to add an `answer_end` value as well. We will write the code to do so in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV7gXjw2WQ3l"
      },
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        answer_text = answer['text']\n",
        "        start_idx = answer['answer_start']\n",
        "        # then the end index is:\n",
        "        end_idx = start_idx + len(answer_text)\n",
        "\n",
        "        # fact: sometimes squad answers are off by a character or two, so\n",
        "        # we will hard-code the following based on the fact above about the SQuAD\n",
        "\n",
        "        # if answer is captured correctly within the start and end indices\n",
        "        if context[start_idx:end_idx] == answer_text:\n",
        "            answer['answer_end'] = end_idx\n",
        "        # otherwise:\n",
        "        else:\n",
        "            # this means the answer is off by 1-2 tokens\n",
        "            for n in [1, 2]:\n",
        "                if context[start_idx-n:end_idx-n] == answer_text:\n",
        "                    answer['answer_start'] = start_idx - n\n",
        "                    answer['answer_end'] = end_idx - n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8wOM24WYsYP"
      },
      "source": [
        "# apply the function to our two answer lists\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(val_answers, val_contexts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovwx4RnFY8x5"
      },
      "source": [
        "Let's check if that worked as well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FCHTOmDY2VV",
        "outputId": "97432b8e-c6cc-4cdc-a1ee-bda8214bc67b"
      },
      "source": [
        "train_answers[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer_end': 286, 'answer_start': 269, 'text': 'in the late 1990s'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MseUF3i1XXZZ"
      },
      "source": [
        "Expected output:\n",
        "\n",
        "`{'answer_end': 286, 'answer_start': 269, 'text': 'in the late 1990s'}`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwyucsFrZDau"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYvKsC8vZmTI"
      },
      "source": [
        "We are almost done preparing the data. We just need to convert our strings into tokens and then translate our `answer_start` and `answer_end` indices from character-position to token-position.\n",
        "\n",
        "Tokenization is easily done using a built-in HuggingFace tokenizer like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "011EnCH1aZDh"
      },
      "source": [
        "# from transformers import BertTokenizerFast\n",
        "from transformers import DistilBertTokenizerFast\n",
        "\n",
        "# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1-wGFuyZJlE"
      },
      "source": [
        "Our context-question pairs are now represented as Encoding objects. These objects merge each corresponding context and question strings to create the Q&A format expected by BERT, which is simply both context and question concatenated but separated with a `[SEP]` token:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "6k8uySCBbmD4",
        "outputId": "57b31e3c-bcd4-4efa-fca6-39a77893016d"
      },
      "source": [
        "tokenizer.decode(train_encodings['input_ids'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] beyonce giselle knowles - carter ( / biːˈjɒnseɪ / bee - yon - say ) ( born september 4, 1981 ) is an american singer, songwriter, record producer and actress. born and raised in houston, texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of r & b girl - group destiny\\'s child. managed by her father, mathew knowles, the group became one of the world\\'s best - selling girl groups of all time. their hiatus saw the release of beyonce\\'s debut album, dangerously in love ( 2003 ), which established her as a solo artist worldwide, earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \". [SEP] when did beyonce start becoming popular? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7alLl1Pb9Cu"
      },
      "source": [
        "This concatenated version is stored within the input_ids attribute of our encoding object. But, rather than the human-readable text, the data is stored as BERT-readable token IDs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1NXN-drvliz",
        "outputId": "3e10dfb2-c3b7-4367-988c-7eefba3b67d1"
      },
      "source": [
        "train_encodings.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7LH8m3-vm5Z"
      },
      "source": [
        "The tokenizer is great, but it doesn’t produce our answer start and end token positions (**start_positions** and **end_positions**) which we need to have in our encoding object which the model will need to train on. For that, we define a custom add_token_positions function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5JE-aVVerVI"
      },
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    for i in range(len(answers)):\n",
        "        # append start/end token position using char_to_token method\n",
        "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
        "\n",
        "        # if start position is None, the answer passage has been truncated\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        # end position cannot be found, char_to_token found space, so shift position until found\n",
        "        shift = 1\n",
        "        while end_positions[-1] is None:\n",
        "            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n",
        "            shift += 1\n",
        "    # update our encodings object with the new token-based start/end positions\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNDZtvFne9kx"
      },
      "source": [
        "# apply function to our data\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGmKDNEjfDXf"
      },
      "source": [
        "Now our encoding objects have two more extra attributes: `start_positions` and `end_positions`. Each of these is simply a list containing the start/end token positions of the answer that corresponds to their respective question-context pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dVeY6E8fVuI",
        "outputId": "3ac5bcd0-cdb6-4da3-bffc-dc58df6b333c"
      },
      "source": [
        "train_encodings.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'start_positions', 'end_positions'])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLr-noN4YACu"
      },
      "source": [
        "Expected output\n",
        "\n",
        "`dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvNALxNUfrog"
      },
      "source": [
        "With that our data is ready!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5-3t1K0flPv"
      },
      "source": [
        "## Initializing the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFtHvFdAfp6_"
      },
      "source": [
        "We are now ready to transform our data into the correct format for training with PyTorch. For this, we need to build a dataset object so we can feed them into our model during training and validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzn-Zn8efpg-"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SquadDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4QIu7tp16cU"
      },
      "source": [
        "Build datasets for both our training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX8gDqAv1-6c"
      },
      "source": [
        "train_dataset = SquadDataset(train_encodings)\n",
        "val_dataset = SquadDataset(val_encodings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4MLeIMO2DQN"
      },
      "source": [
        "(Optional) Build partial datasets for both our training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVcJk2A32HEV"
      },
      "source": [
        "import torch.utils.data as data_utils\n",
        "\n",
        "train_dataset = data_utils.Subset(train_dataset, torch.arange(10000))\n",
        "val_dataset = data_utils.Subset(val_dataset, torch.arange(1000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0R0ZtPl2Bla",
        "outputId": "8035a52a-b545-4a4d-fe17-94da211f59b9"
      },
      "source": [
        "print(\"length train:\", len(train_dataset))\n",
        "print(\"length val:\", len(val_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length train: 10000\n",
            "length val: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VlvaTcrwZ9c"
      },
      "source": [
        "## Fine-Tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnKCFGVKit-O"
      },
      "source": [
        "As usual we first initialize our `DataLoader` for train and validation which we'll be using to load data during training and fine-tuning our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6q-rU-2wcyn"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZFiHWhEj443",
        "outputId": "7687056a-6f4a-4402-9a99-c17ea75fb60e"
      },
      "source": [
        "# setup GPU/CPU, for this assignment it is recommended to use GPU (cuda)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65h4nDa-IUHh",
        "outputId": "c5017cfb-a69a-4c1a-abf0-727c5dd34e50"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL7NbxAR9hln"
      },
      "source": [
        "from transformers import BertForQuestionAnswering\n",
        "from transformers import DistilBertForQuestionAnswering\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm, trange\n",
        "from seqeval.metrics import f1_score, accuracy_score\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoRq4PcXExzl",
        "outputId": "32be29c1-50aa-4bb5-f7b1-cef1ea6c62fa"
      },
      "source": [
        "# initialize model for QA\n",
        "# model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
        "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNadLRwNoENj",
        "outputId": "ab62a6bc-dd24-491a-e278-fb46c8e4e1c3"
      },
      "source": [
        "# move model over to detected device\n",
        "model.to(device)\n",
        "\n",
        "# initialize adam optimizer with weight decay (reduces chance of overfitting)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "\n",
        "# set epochs\n",
        "epochs = 3\n",
        "\n",
        "num_samples = len(train_dataset)\n",
        "batches_per_epoch = int(num_samples/batch_size)\n",
        "gradient_accumulation_steps = 1\n",
        "total_steps = int(epochs*batches_per_epoch/gradient_accumulation_steps)\n",
        "warmup_steps = int(0.1*total_steps)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "## Store the average loss after each epoch so we can plot them.\n",
        "loss_values, validation_loss_values = [], []\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    train_losses = 0\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        # Put the model into training mode\n",
        "        model.train()\n",
        "\n",
        "        # pull all the tensor batches required for training\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "\n",
        "        # train model\n",
        "        outputs = model(input_ids, \n",
        "                        attention_mask=attention_mask,\n",
        "                        start_positions=start_positions,\n",
        "                        end_positions=end_positions)\n",
        "        # track loss\n",
        "        loss = outputs.loss/gradient_accumulation_steps\n",
        "        loss.backward()\n",
        "        train_losses += loss.item()\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        model.zero_grad()\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data\n",
        "    avg_train_loss = train_losses / len(train_loader)\n",
        "    print(\"train loss: {}\".format(avg_train_loss))\n",
        "\n",
        "    # Store the loss value for plotting the learning curve\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print('Evaluating...')\n",
        "    val_losses = 0\n",
        "    predictions , true_labels = [], []\n",
        "    acc = []\n",
        "    for batch in val_loader:\n",
        "        # Put the model into evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Telling the model not to compute or store gradients,\n",
        "        # saving memory and speeding up validation\n",
        "        with torch.no_grad():\n",
        "            # pull batched items from loader\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            start_true = batch['start_positions'].to(device)\n",
        "            end_true = batch['end_positions'].to(device)\n",
        "\n",
        "            # make predictions\n",
        "            outputs = model(input_ids, \n",
        "                            attention_mask=attention_mask,\n",
        "                            start_positions=start_true,\n",
        "                            end_positions=end_true)\n",
        "            \n",
        "            # track loss\n",
        "            loss = outputs.loss\n",
        "            val_losses += loss.item()\n",
        "\n",
        "            # pull prediction tensors out and argmax to get predicted tokens\n",
        "            start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "            end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "            # calculate accuracy for both and append to accuracy list\n",
        "            acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
        "            acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
        "\n",
        "    # Calculate the average loss over the training data\n",
        "    avg_val_loss = val_losses / len(val_loader)\n",
        "    print(\"val_loss: {}\".format(avg_val_loss))\n",
        "\n",
        "    # calculate accuracy\n",
        "    acc = sum(acc)/len(acc)\n",
        "    print(\"Validation Accuracy: {}\".format(acc))\n",
        "\n",
        "    # Store the val loss value for plotting the learning curve\n",
        "    validation_loss_values.append(avg_val_loss)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 2.478915125322342\n",
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  33%|███▎      | 1/3 [17:26<34:53, 1046.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss: 1.8885453548431397\n",
            "Validation Accuracy: 0.4885\n",
            "\n",
            "train loss: 0.9362878883957862\n",
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  67%|██████▋   | 2/3 [34:54<17:27, 1047.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss: 1.852135550737381\n",
            "Validation Accuracy: 0.522\n",
            "\n",
            "train loss: 0.4579455568432808\n",
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 3/3 [52:21<00:00, 1047.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss: 2.1260898740291596\n",
            "Validation Accuracy: 0.533\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEHBd39RC5Mp"
      },
      "source": [
        "Let's save our model so we can use it in the next session!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_eadF5tC89h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193e07d1-1901-4c58-f21b-5eb2a5e9e0a4"
      },
      "source": [
        "# model_path = 'models/bert-custom'\n",
        "model_path = 'models/distilbert-custom'\n",
        "\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('models/distilbert-custom/tokenizer_config.json',\n",
              " 'models/distilbert-custom/special_tokens_map.json',\n",
              " 'models/distilbert-custom/vocab.txt',\n",
              " 'models/distilbert-custom/added_tokens.json',\n",
              " 'models/distilbert-custom/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPK1sugzwh-z"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qR3NaBnPXc5"
      },
      "source": [
        "Load the saved model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFnZpS12wjOs"
      },
      "source": [
        "# model = BertForQuestionAnswering.from_pretrained(model_path)\n",
        "# tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
        "\n",
        "model = DistilBertForQuestionAnswering.from_pretrained(model_path)\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnAeN4o2kBzZ"
      },
      "source": [
        "def question_answer(question, text):\n",
        "    \n",
        "    # tokenize question and text as a pair\n",
        "    input_ids = tokenizer.encode(question, text)\n",
        "    \n",
        "    # string version of tokenized ids\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "    \n",
        "    # segment IDs\n",
        "    # first occurence of [SEP] token\n",
        "    sep_idx = input_ids.index(tokenizer.sep_token_id)    \n",
        "    # number of tokens in segment A (question)\n",
        "    num_seg_a = sep_idx+1    \n",
        "    # number of tokens in segment B (text)\n",
        "    num_seg_b = len(input_ids) - num_seg_a\n",
        "    \n",
        "    # list of 0s and 1s for segment embeddings\n",
        "    segment_ids = [0]*num_seg_a + [1]*num_seg_b \n",
        "    assert len(segment_ids) == len(input_ids)\n",
        "    \n",
        "    # model output using input_ids\n",
        "    ## for bert (+ using token_type_ids)\n",
        "    if isinstance(model, BertForQuestionAnswering):\n",
        "      output = model(torch.tensor([input_ids], token_type_ids=torch.tensor([segment_ids])))\n",
        "    elif isinstance(model, DistilBertForQuestionAnswering):\n",
        "      output = model(torch.tensor([input_ids]))\n",
        "    else:\n",
        "      raise \"Inference code does not suport model!\"\n",
        "    \n",
        "    # reconstructing the answer\n",
        "    answer_start = torch.argmax(output.start_logits, dim=1)\n",
        "    answer_end = torch.argmax(output.end_logits, dim=1)\n",
        "\n",
        "    # again, because BERT uses wordpiece tokenization...\n",
        "    answer = ''  \n",
        "    if answer_end >= answer_start:\n",
        "        answer = tokens[answer_start]\n",
        "        for i in range(answer_start+1, answer_end+1):\n",
        "            if tokens[i][0:2] == \"##\":\n",
        "                answer += tokens[i][2:]\n",
        "            else:\n",
        "                answer += \" \" + tokens[i]\n",
        "                \n",
        "    if answer.startswith(\"[CLS]\"):\n",
        "        answer = \"Unable to find the answer to your question.\"\n",
        "    \n",
        "    print(\"\\nPredicted answer:\\n{}\".format(answer.capitalize()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_eBmAYFjE62"
      },
      "source": [
        "text = \"\"\"\n",
        "my name is Hasan, I like machine learning.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zinOtu8-jbWh"
      },
      "source": [
        "question = \"What does hasan like?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr4z46LFl7kk",
        "outputId": "a53807fb-8255-4dd4-f6bb-d0b42c8b9dec"
      },
      "source": [
        "question_answer(question, text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted answer:\n",
            "Machine learning .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pplp4A5W6urA"
      },
      "source": [
        "# This might be able to download the model folder \n",
        "from google.colab import files\n",
        "files.download(model_path) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}