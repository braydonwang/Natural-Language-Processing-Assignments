{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Pytorch_DataLoaders_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM5c_vCCON5R"
      },
      "source": [
        "# \"An Essentials Guide to PyTorch Dataset and DataLoader Usage\"\n",
        "> \"A brief guide for basic usage of PyTorch's Dataset and DataLoader classes.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8ZXflz7ON5U"
      },
      "source": [
        "## Overview\n",
        "In this short guide, we show a small representative example using the `Dataset` and `DataLoader` classes available in PyTorch for easy batching of training examples. This is more meant to be an onboarding for me with `fastpages`, but hopefully this example will be useful to those beginning to use PyTorch for their own applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5y2i7svON5V"
      },
      "source": [
        "## Setup\n",
        "The first thing we need is the essential import: `torch`, i.e. PyTorch. Make sure that when you're running a notebook with code similar to this that you've imported `torch`, i.e. `import torch`, as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imtY2PbCON5V"
      },
      "source": [
        "#collapse_hide\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AshyQRdDON5W"
      },
      "source": [
        "We'll then need a dataset to work with. For this small example, we'll use `numpy` to generate a random dataset for us. Specifically, we'll be working with a batch size of 32 later, so we'll create a dataset with exactly 50 batches, where each example has 5 features and a corresponding label between 0-9, inclusive. To do so, we use\n",
        "\n",
        "* `np.random.randn` for generating the input examples\n",
        "* `np.random.randint` for generating the labels\n",
        "\n",
        "The exact code is shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-HS4PojON5X"
      },
      "source": [
        "#collapse_show\n",
        "import numpy as np\n",
        "\n",
        "training_examples = np.random.randn(32 * 50, 5)\n",
        "training_labels = np.random.randint(0, 10, size=(32*50,))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3LAPn26Yvvn"
      },
      "source": [
        "# training_labels"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdTrMf1cON5X"
      },
      "source": [
        "As a sanity check, let's look at the shapes. We'll want the size of the *whole* dataset to be (1600, 5), as we have $32*50$ examples, each with 5 features. Similarly, we'll want the size of the labels for the whole dataset to be (1600,), as we're essentially working with a list of 1600 labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfOLx6jzON5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96c7ff4c-398f-4684-f5df-40d438521280"
      },
      "source": [
        "#collapse_show\n",
        "training_examples.shape, training_labels.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1600, 5), (1600,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eVJSd4WON5b"
      },
      "source": [
        "We can look at some of the labels, just for a sanity check that they look reasonable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2wQ0inyON5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73ae911-6833-4f6f-d72a-2fdf0952cf19"
      },
      "source": [
        "#collapse_show\n",
        "training_labels[:10]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 4, 2, 0, 9, 4, 8, 7, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQte4-XxZ8yo"
      },
      "source": [
        "#intro to classes\n",
        "class SampleClass():\n",
        "  def __init__(self, A, B):\n",
        "    self.A = A\n",
        "    self.B = B\n",
        "\n",
        "  def add_(self):\n",
        "    return self.A+self.B"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F65z8R7laPVJ"
      },
      "source": [
        "instance_10 = SampleClass(10, 10)\n",
        "instance_20 = SampleClass(20,20)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wL_IZpvaf00",
        "outputId": "a9780cca-b21a-4182-8aa4-c5d6a125bb17"
      },
      "source": [
        "instance_10.add_()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBx6t1yUanK6",
        "outputId": "93163475-b50a-465b-eeaf-eb6c7d2df69b"
      },
      "source": [
        "instance_20.A"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOCVPymMON5e"
      },
      "source": [
        "## Dataset Class and Instantiation\n",
        "Now, we'll create a simple PyTorch dataset class. All you need to implement within this class is the `__getitem__` function and the `__len__` function.\n",
        "\n",
        "* `__getitem__` is a function that takes in an index, and returns `dataset[index]`\n",
        "* `__len__` returns the size of your dataset (in this case, that's 32*50).\n",
        "\n",
        "When writing this class, you MUST subclass `torch.utils.data.Dataset`, as this is requirement for using the DataLoader class (see below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXW46WbDON5f"
      },
      "source": [
        "class ExampleDataset(torch.utils.data.Dataset):\n",
        "    \"\"\" You can define the __init__ function any way you like\"\"\"\n",
        "    def __init__(self, examples, labels):\n",
        "        self.examples = examples\n",
        "        self.labels = labels\n",
        "\n",
        "    \"\"\" This function signature always should take in 1 argument, corresponding to the index you're going to access.\n",
        "        In this case, we're returning a tuple, corresponding to the training example and the corresponding label. \n",
        "        \n",
        "        It will also be useful to convert the returned values to torch.Tensors, so we can push the data onto the\n",
        "        GPU later on. Note how the label is put into an array, but the example isn't. This is just a convention:\n",
        "        if we don't put `self.labels[index]` in a list, it'll just create a tensor of zeros with `self.labels[index]` zeros.\n",
        "        \"\"\"\n",
        "    def __getitem__(self, index):\n",
        "        return (torch.Tensor(self.examples[index]), torch.Tensor([self.labels[index]]))\n",
        "\n",
        "    \"\"\" This function signature always should take in 0 arguments, and the output should be an `int`. \"\"\"\n",
        "    def __len__(self):\n",
        "        return len(self.examples)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDu2Rv4-ON5f"
      },
      "source": [
        "Now, we can instantiate an instance of our `ExampleDataset` class, which subclasses `torch.utils.data.Dataset`. Note that we can specify how to initialize this via the `__init__` function, which takes in a list of examples, and a list of labels (i.e. what we've instantiated in our own setup)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zip6PKoHON5g"
      },
      "source": [
        "training_dataset = ExampleDataset(training_examples, training_labels)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTCwj13oON5g"
      },
      "source": [
        "Sanity check - see the correspondence between accessing the dataset instance of the class above and the examples/labels we passed in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwmld-4qON5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10055d15-852f-40b2-931d-6d2f0f0f6d77"
      },
      "source": [
        "training_dataset[10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.2081,  1.1126, -0.5038,  0.5285,  0.8456]), tensor([3.]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgD8ttUvON5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af240efe-bf08-4398-df44-43d60de2629b"
      },
      "source": [
        "training_examples[10], training_labels[10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.20808636,  1.11255702, -0.50383772,  0.52846881,  0.84555002]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYZWOOHaON5i"
      },
      "source": [
        "We can iterate over this dataset using standard for loop syntax as well. The way you write the for loop depends on how `__getitem__` is set up. In our case, we return a tuple (example and label), so the for loop should also have a tuple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1nshkHnON5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8e21cd-296c-408e-ac25-90305b58f656"
      },
      "source": [
        "example, label = training_dataset[0]\n",
        "print(type(example), example.shape, type(label), label.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> torch.Size([5]) <class 'torch.Tensor'> torch.Size([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb-K8ux3ON5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5903c071-43ff-4a88-ff5f-9ff46314022e"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for example, label in tqdm(training_dataset):\n",
        "    continue"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1600/1600 [00:00<00:00, 80719.84it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ_2KfeAcaMf"
      },
      "source": [
        "### EXAMPLE ###\n",
        "model = Model()\n",
        "\n",
        "for example, labels in tqdm(training_dataset):\n",
        "  pred_label = model(example)\n",
        "\n",
        "  loss = loss_function(pred_label, label)\n",
        "  update.model\n",
        "  update_gradient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvch8r7xON5k"
      },
      "source": [
        "## Batching via the DataLoader class\n",
        "To set up batching, we'll use the `torch.utils.data.DataLoader` class. All we have to do to create this DataLoader is to instantiate it with our dataset we created above (`training_dataset`). The arguments for `torch.utils.data.DataLoader` are worth looking at, but (generally) most important are:\n",
        "\n",
        "* `dataset`: the PyTorch dataset class instance we'll pass in (e.g. `training_dataset`, this is why we had to do subclassing above)\n",
        "* `batch_size` (optional, default is 1): the batch size we want when iterating (we'll pass in 32)\n",
        "* `shuffle` (optional, default is `False`): whether we want to shuffle when iterating once the dataloader (note that if this is set to true, it'll shuffle every epoch; note also that we only really want to have this set to true for training, not necessarily for validation)\n",
        "* `drop_last` (optional, default is `False`): whether to drop the last incomplete batch (we don't have to worry about this because the number of training examples is exactly divisible by 32)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7EUMz3WON5k"
      },
      "source": [
        "training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=16, shuffle=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BQgG7meex9w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOfDzcrhON5l"
      },
      "source": [
        "Again, we can iterate, just like we did for `training_dataset`, but now, we get batches back, as we can see by printing the shapes. The magic happens in the `collate_fn` optional argument of the DataLoader class, but the default behavior is sufficient here for batching the examples and labels separately.\n",
        "\n",
        "We'll first ensure that there are exactly 50 batches in our dataloader to work with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukdl77jYON5l"
      },
      "source": [
        "assert len(training_dataloader) == 100, \"Length is not the same\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTj1Y9tAON5l"
      },
      "source": [
        "Now, mimicking the iteration from above, with the `ExampleDataset` instance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcKtkHohON5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b95c04-4a27-481d-eefc-3e0821d5c806"
      },
      "source": [
        "for example, label in tqdm(training_dataloader):\n",
        "    continue"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 2643.70it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW4BcBYvON5m"
      },
      "source": [
        "At some point, you may want to know information about a specific batch - accessing specific batches from the DataLoader is not as easy - I don't know of a way to grab a specific batch, other than doing something like the following."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDMIPSA5ON5m"
      },
      "source": [
        "training_dataloader_batches = [(example, label) for example, label in training_dataloader]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYL3P0mWON5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7469b280-5e01-4f55-8dcf-a56f8e998c92"
      },
      "source": [
        "some_example, some_label = training_dataloader_batches[15]\n",
        "some_example.shape, some_label.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 5]), torch.Size([16, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJTx6PTPON5m"
      },
      "source": [
        "However, you can always access the underlying dataset by literally doing `.dataset`, as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fQmpfSUON5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d2a52b4-8481-4a71-b351-3cbb29f84041"
      },
      "source": [
        "training_dataloader.dataset"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.ExampleDataset at 0x7f483ca0fed0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvKVXXPbON5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5baca26b-f450-4039-c9b1-c3383e495e72"
      },
      "source": [
        "training_dataloader.dataset[15]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.9917, 0.0619, 0.2384, 2.1653, 0.8300]), tensor([6.]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLMZepDJON5o"
      },
      "source": [
        "## Afterword and Resources\n",
        "\n",
        "As mentioned above, it's useful to look at the [documentation](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) for `torch.utils.data.DataLoader`. Another way to do so within the notebook itself is to run the following within a cell of the notebook:\n",
        "\n",
        "```\n",
        "torch.utils.data.DataLoader?\n",
        "```\n",
        "\n",
        "There are many interesting things that you can do here, with the arguments allowed in the DataLoader. For example:\n",
        "* You may be working with an image dataset large enough that you don't want to open all the images (e.g. using `PIL`) before feeding them through your model. In that case, you can lazily open them by passing in a `collate_fn` that opens the images before collating the examples of a batch, since `collate_fn` is only called for each iteration when iterating over the DataLoader, and not when the DataLoader is instantiated.\n",
        "* You may not want to `shuffle` the dataset, as it might incur unnecessary computation. This is especially true if you have a separate DataLoader for your validation dataset, in which case there's no need to shuffle, as it won't affect the predictions.\n",
        "* If you have access to multiple CPUs on whatever machine you're working on, you can use `num_workers` to load batches ahead of time on the other CPUs, i.e. the other workers.\n",
        "* If you're working with a GPU, one of the more expensive steps in the pipeline is moving data from CPU to GPU - this can be sped up by using `pin_memory`, which ensures that the same space in the GPU RAM is used for the data being transferred from the CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IARXmElSON5o"
      },
      "source": [
        "torch.utils.data.DataLoader?"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoReoykHjI-m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}